from faster_whisper import WhisperModel

def load_model_safe(model_size="small"):
    try:
        print(f"ğŸš€ æ­£åœ¨å°è¯•ç”¨GPUåŠ è½½ {model_size} æ¨¡å‹...")
        model = WhisperModel(model_size, device="cuda", compute_type="float16")
        print("âœ… æˆåŠŸä½¿ç”¨GPUåŠ è½½")
    except Exception as e:
        print(f"âŒ GPUåŠ è½½å¤±è´¥ï¼Œé”™è¯¯: {e}")
        print("âš™ï¸ åˆ‡æ¢åˆ°CPUåŠ è½½ï¼ˆæ…¢ä¸€ç‚¹ï¼‰...")
        model = WhisperModel(model_size, device="cpu", compute_type="int8")
    return model

if __name__ == "__main__":
    model = load_model_safe("tiny")
    segments, info = model.transcribe("./audio_recording/61-70970-0000.flac",language="zh",  task="transcribe",)
    for segment in segments:
        print(f"[{segment.start:.2f} --> {segment.end:.2f}] {segment.text}")

    # segments =None,
    # info = None
    # segments, info = model.transcribe("./video/1.mp3",language="zh", task="translate",)
    # for segment in segments:
    #     print(f"[{segment.start:.2f} --> {segment.end:.2f}] {segment.text}")
